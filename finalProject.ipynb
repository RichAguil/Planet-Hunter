{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   koi_period  koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  \\\n",
      "0    9.488036   170.538750       0.146       2.95750      616.0      2.26   \n",
      "1   54.418383   162.513840       0.586       4.50700      875.0      2.83   \n",
      "2   19.899140   175.850252       0.969       1.78220    10800.0     14.60   \n",
      "3    1.736952   170.307565       1.276       2.40641     8080.0     33.46   \n",
      "4    2.525592   171.595550       0.701       1.65450      603.0      2.75   \n",
      "\n",
      "   koi_incl  koi_teq  koi_model_snr koi_disposition  koi_steff  koi_slogg  \\\n",
      "0     89.66    793.0           35.8       CONFIRMED     5455.0      4.467   \n",
      "1     89.57    443.0           25.8       CONFIRMED     5455.0      4.467   \n",
      "2     88.96    638.0           76.3       CANDIDATE     5853.0      4.544   \n",
      "3     67.09   1395.0          505.6  FALSE POSITIVE     5805.0      4.564   \n",
      "4     85.41   1406.0           40.9       CONFIRMED     6031.0      4.438   \n",
      "\n",
      "   koi_smet  koi_srad  koi_smass  \n",
      "0      0.14     0.927      0.919  \n",
      "1      0.14     0.927      0.919  \n",
      "2     -0.18     0.868      0.961  \n",
      "3     -0.52     0.791      0.836  \n",
      "4      0.07     1.046      1.095  \n",
      "(9564, 15)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "keplerDF = pd.read_csv('Kepler_Data_Final_Project.csv')\n",
    "print(keplerDF.head(5))\n",
    "print(keplerDF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The koi_disposition will be the target vector. However, it cannot be used as it is now, since it contains non-numerical data. Here I will convert every instance of \"CONFIRMED\" to the binary value of 1, and the \"FALSE POSITIVE\" to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9564, 15)\n"
     ]
    }
   ],
   "source": [
    "keplerDF.loc[keplerDF['koi_disposition'] == 'CONFIRMED', ['koi_disposition']] = 1\n",
    "keplerDF.loc[keplerDF['koi_disposition'] == 'FALSE POSITIVE', ['koi_disposition']] = 0\n",
    "print(keplerDF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most of the planets have either been confirmed or labeled false positive, some are still pending, and labeled as \"CANDIDATE\". As such, those rows that contain potential planets whos final status are still unknown, will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7198, 15)\n"
     ]
    }
   ],
   "source": [
    "keplerDF.drop(keplerDF[keplerDF['koi_disposition'] == 'CANDIDATE'].index, inplace = True)\n",
    "print(keplerDF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6919, 15)\n"
     ]
    }
   ],
   "source": [
    "keplerDF.dropna(inplace = True)\n",
    "print(keplerDF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An addition, the properties of the host star must be split off from the planetary transit data. The steller properties will be used later for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   koi_period  koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  \\\n",
      "0    9.488036   170.538750       0.146       2.95750      616.0      2.26   \n",
      "1   54.418383   162.513840       0.586       4.50700      875.0      2.83   \n",
      "3    1.736952   170.307565       1.276       2.40641     8080.0     33.46   \n",
      "4    2.525592   171.595550       0.701       1.65450      603.0      2.75   \n",
      "5   11.094321   171.201160       0.538       4.59450     1520.0      3.90   \n",
      "\n",
      "   koi_incl  koi_teq  koi_model_snr koi_disposition  \n",
      "0     89.66    793.0           35.8               1  \n",
      "1     89.57    443.0           25.8               1  \n",
      "3     67.09   1395.0          505.6               0  \n",
      "4     85.41   1406.0           40.9               1  \n",
      "5     88.11    835.0           66.5               1  \n",
      "(6919, 10)\n"
     ]
    }
   ],
   "source": [
    "#keplerDF.columns = keplerDF.iloc[0]\n",
    "#keplerDF = keplerDF[1:]\n",
    "stellarDF = keplerDF.iloc[:,-5:]\n",
    "planetaryDF = keplerDF.iloc[:,:-5]\n",
    "print(planetaryDF.head(5))\n",
    "print(planetaryDF.shape) #Planetary data shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   koi_steff  koi_slogg  koi_smet  koi_srad  koi_smass\n",
      "0     5455.0      4.467      0.14     0.927      0.919\n",
      "1     5455.0      4.467      0.14     0.927      0.919\n",
      "3     5805.0      4.564     -0.52     0.791      0.836\n",
      "4     6031.0      4.438      0.07     1.046      1.095\n",
      "5     6046.0      4.486     -0.08     0.972      1.053\n",
      "(6919, 5)\n"
     ]
    }
   ],
   "source": [
    "print(stellarDF.head(5))\n",
    "print(stellarDF.shape) #Stellar data shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target vector: (6919,)\n",
      "Shape of features: (6919, 9)\n"
     ]
    }
   ],
   "source": [
    "#planetaryDF = shuffle(planetaryDF)\n",
    "Y = planetaryDF.loc[:, 'koi_disposition'] #splitting the data into features and target vector\n",
    "X_Planetary = planetaryDF.loc[:, :'koi_model_snr']\n",
    "print(\"Shape of target vector:\", Y.shape)\n",
    "print(\"Shape of features:\", X_Planetary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine\n",
    "### Standardization and splitting the dataset\n",
    "Given the wide spread in the range of our features, in addition to the difference in measurement units, it is necessary to standardize them, so that the mere magnitude of a particular feature will not dominate the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X_Planetary, Y, test_size = 0.30)\n",
    "SVM_classifier = LinearSVC(C = 1, loss = \"hinge\", max_iter = 1000000)\n",
    "scaledSVM = Pipeline([(\"scaler\", scaler), (\"linearClassifier\", SVM_classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing the Soft SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4843,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linearClassifier',\n",
       "                 LinearSVC(C=1, loss='hinge', max_iter=1000000))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Train = Y_Train.astype('int64') #The values must be of the same type (in this case type 'int'), otherwise, this model will not run\n",
    "print(Y_Train.shape)\n",
    "scaledSVM.fit(X_Train, Y_Train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1150  251]\n",
      " [ 111  564]]\n",
      "\n",
      "Accuracy: 82.56%\n",
      "F1 score: 75.70%\n"
     ]
    }
   ],
   "source": [
    "predictedValues = scaledSVM.predict(X_Test)\n",
    "Y_Test = Y_Test.astype('int64')\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(Y_Test, predictedValues))\n",
    "print()\n",
    "print(\"Accuracy:\", \"{:.2%}\".format(accuracy_score(Y_Test, predictedValues)))\n",
    "print(\"F1 score:\", \"{:.2%}\".format(f1_score(Y_Test, predictedValues)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Optimal C for Soft-margin SVM\n",
    "Given the classificaton report, it is clear that C, the penalty parameter, is not adequate. This parameter is used as a trade-off value between misclassifications and the margin size. The smaller the value of C, the larger the tolerance for misclassification, resulting in a larger margin. The higher the C, the lesser the tolerance for misclassification, resulting in a smaller margin. Therefore, a higher C brings the model closer to a 'hard' SVM. Therefore, C will be the hyperparameter that will be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 55, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.829 (+/-0.023) for {'C': 1, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.832 (+/-0.023) for {'C': 3, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.833 (+/-0.021) for {'C': 5, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.834 (+/-0.020) for {'C': 7, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.835 (+/-0.020) for {'C': 9, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.836 (+/-0.021) for {'C': 11, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.836 (+/-0.022) for {'C': 13, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.836 (+/-0.023) for {'C': 15, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.837 (+/-0.023) for {'C': 17, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.838 (+/-0.021) for {'C': 19, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.837 (+/-0.022) for {'C': 21, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.838 (+/-0.022) for {'C': 23, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.837 (+/-0.023) for {'C': 25, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.838 (+/-0.023) for {'C': 27, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.838 (+/-0.022) for {'C': 29, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.838 (+/-0.022) for {'C': 31, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.838 (+/-0.021) for {'C': 33, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.838 (+/-0.021) for {'C': 35, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.021) for {'C': 37, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.022) for {'C': 39, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.022) for {'C': 41, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.022) for {'C': 43, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.022) for {'C': 45, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.021) for {'C': 47, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.022) for {'C': 49, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.021) for {'C': 51, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.021) for {'C': 53, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.020) for {'C': 55, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.020) for {'C': 57, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.020) for {'C': 59, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.019) for {'C': 61, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.019) for {'C': 63, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.020) for {'C': 65, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.839 (+/-0.020) for {'C': 67, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "0.840 (+/-0.019) for {'C': 69, 'loss': 'hinge', 'max_iter': 1000000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1401\n",
      "           1       0.76      0.66      0.70       675\n",
      "\n",
      "    accuracy                           0.82      2076\n",
      "   macro avg       0.80      0.78      0.79      2076\n",
      "weighted avg       0.82      0.82      0.82      2076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_list = [(i*2)+1 for i in range(35)]\n",
    "X_Train = scaler.fit_transform(X_Train)\n",
    "X_Test = scaler.fit_transform(X_Test)\n",
    "tuned_parameters = [{'max_iter': [1000000], 'loss':['hinge'], 'C': C_list}]\n",
    "\n",
    "print(\"Tuning hyper-parameters for accuracy\")\n",
    "print()\n",
    "linearSVM = GridSearchCV(LinearSVC(), tuned_parameters, scoring = 'accuracy')\n",
    "linearSVM.fit(X_Train, Y_Train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(linearSVM.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = linearSVM.cv_results_['mean_test_score']\n",
    "stds = linearSVM.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, linearSVM.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "actualValues, predictedValues = Y_Test, linearSVM.predict(X_Test)\n",
    "print(classification_report(actualValues, predictedValues))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1257  144]\n",
      " [ 231  444]]\n",
      "\n",
      "Accuracy: 81.94%\n",
      "F1 score: 70.31%\n"
     ]
    }
   ],
   "source": [
    "linearSVM = LinearSVC(C = 55, loss = \"hinge\", max_iter = 1000000)\n",
    "linearSVM.fit(X_Train, Y_Train.values.ravel())\n",
    "predictedValues = linearSVM.predict(X_Test)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(Y_Test, predictedValues))\n",
    "print()\n",
    "print(\"Accuracy:\", \"{:.2%}\".format(accuracy_score(Y_Test, predictedValues)))\n",
    "print(\"F1 score:\", \"{:.2%}\".format(f1_score(Y_Test, predictedValues)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernalized Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel\n",
    "### Hyperparameter Tuning (GridSearchCV)\n",
    "To elevate the samples into a higher-dimension, the polynomial kernelized SVM uses a polynomial function of N-degree. In this optimization, several values of d will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 59, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.823 (+/-0.015) for {'C': 1, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.804 (+/-0.018) for {'C': 1, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.774 (+/-0.035) for {'C': 1, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.662 (+/-0.005) for {'C': 1, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.662 (+/-0.008) for {'C': 1, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.827 (+/-0.017) for {'C': 3, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.814 (+/-0.020) for {'C': 3, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.815 (+/-0.026) for {'C': 3, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.714 (+/-0.070) for {'C': 3, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.662 (+/-0.011) for {'C': 3, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.829 (+/-0.017) for {'C': 5, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.817 (+/-0.020) for {'C': 5, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.820 (+/-0.023) for {'C': 5, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.776 (+/-0.055) for {'C': 5, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.663 (+/-0.012) for {'C': 5, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.016) for {'C': 7, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.819 (+/-0.024) for {'C': 7, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.822 (+/-0.022) for {'C': 7, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.770 (+/-0.050) for {'C': 7, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.663 (+/-0.012) for {'C': 7, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.014) for {'C': 9, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.819 (+/-0.020) for {'C': 9, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.823 (+/-0.020) for {'C': 9, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.770 (+/-0.048) for {'C': 9, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.664 (+/-0.012) for {'C': 9, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.014) for {'C': 11, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.821 (+/-0.021) for {'C': 11, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.825 (+/-0.022) for {'C': 11, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.773 (+/-0.045) for {'C': 11, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.664 (+/-0.014) for {'C': 11, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.013) for {'C': 13, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.822 (+/-0.020) for {'C': 13, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.827 (+/-0.021) for {'C': 13, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.776 (+/-0.038) for {'C': 13, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.669 (+/-0.015) for {'C': 13, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.829 (+/-0.013) for {'C': 15, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.822 (+/-0.019) for {'C': 15, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.826 (+/-0.024) for {'C': 15, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.780 (+/-0.036) for {'C': 15, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.680 (+/-0.027) for {'C': 15, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.830 (+/-0.012) for {'C': 17, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.824 (+/-0.020) for {'C': 17, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.827 (+/-0.026) for {'C': 17, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.786 (+/-0.032) for {'C': 17, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.706 (+/-0.062) for {'C': 17, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 19, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.825 (+/-0.022) for {'C': 19, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.024) for {'C': 19, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.787 (+/-0.033) for {'C': 19, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.741 (+/-0.105) for {'C': 19, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.015) for {'C': 21, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.826 (+/-0.022) for {'C': 21, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.829 (+/-0.023) for {'C': 21, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.790 (+/-0.030) for {'C': 21, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.753 (+/-0.082) for {'C': 21, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.014) for {'C': 23, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.826 (+/-0.023) for {'C': 23, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.829 (+/-0.021) for {'C': 23, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.793 (+/-0.030) for {'C': 23, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.754 (+/-0.078) for {'C': 23, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 25, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.825 (+/-0.022) for {'C': 25, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.018) for {'C': 25, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.795 (+/-0.028) for {'C': 25, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.768 (+/-0.072) for {'C': 25, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 27, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.825 (+/-0.022) for {'C': 27, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.829 (+/-0.019) for {'C': 27, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.796 (+/-0.029) for {'C': 27, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.773 (+/-0.079) for {'C': 27, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.013) for {'C': 29, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.825 (+/-0.019) for {'C': 29, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.829 (+/-0.018) for {'C': 29, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.797 (+/-0.029) for {'C': 29, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.771 (+/-0.090) for {'C': 29, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.013) for {'C': 31, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.825 (+/-0.020) for {'C': 31, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.830 (+/-0.018) for {'C': 31, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.798 (+/-0.028) for {'C': 31, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.770 (+/-0.095) for {'C': 31, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.013) for {'C': 33, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.825 (+/-0.019) for {'C': 33, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.830 (+/-0.018) for {'C': 33, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.799 (+/-0.028) for {'C': 33, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.771 (+/-0.095) for {'C': 33, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.013) for {'C': 35, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.826 (+/-0.020) for {'C': 35, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.019) for {'C': 35, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.800 (+/-0.027) for {'C': 35, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.770 (+/-0.096) for {'C': 35, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.013) for {'C': 37, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.826 (+/-0.019) for {'C': 37, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.018) for {'C': 37, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.801 (+/-0.027) for {'C': 37, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.769 (+/-0.088) for {'C': 37, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.013) for {'C': 39, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.826 (+/-0.021) for {'C': 39, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.020) for {'C': 39, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.802 (+/-0.028) for {'C': 39, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.768 (+/-0.089) for {'C': 39, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 41, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.826 (+/-0.021) for {'C': 41, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.019) for {'C': 41, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.804 (+/-0.029) for {'C': 41, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.767 (+/-0.087) for {'C': 41, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 43, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.827 (+/-0.021) for {'C': 43, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.019) for {'C': 43, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.803 (+/-0.026) for {'C': 43, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.766 (+/-0.088) for {'C': 43, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 45, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.021) for {'C': 45, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.019) for {'C': 45, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.804 (+/-0.026) for {'C': 45, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.766 (+/-0.085) for {'C': 45, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.830 (+/-0.013) for {'C': 47, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.827 (+/-0.022) for {'C': 47, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.018) for {'C': 47, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.805 (+/-0.026) for {'C': 47, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.766 (+/-0.083) for {'C': 47, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 49, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.827 (+/-0.021) for {'C': 49, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.833 (+/-0.017) for {'C': 49, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.807 (+/-0.026) for {'C': 49, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.768 (+/-0.086) for {'C': 49, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.014) for {'C': 51, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.020) for {'C': 51, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.834 (+/-0.014) for {'C': 51, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.807 (+/-0.025) for {'C': 51, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.766 (+/-0.078) for {'C': 51, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 53, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.020) for {'C': 53, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.834 (+/-0.015) for {'C': 53, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.808 (+/-0.024) for {'C': 53, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.767 (+/-0.079) for {'C': 53, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 55, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.020) for {'C': 55, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.834 (+/-0.017) for {'C': 55, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.808 (+/-0.024) for {'C': 55, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.765 (+/-0.075) for {'C': 55, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.831 (+/-0.013) for {'C': 57, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.828 (+/-0.021) for {'C': 57, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.834 (+/-0.017) for {'C': 57, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.809 (+/-0.023) for {'C': 57, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.766 (+/-0.078) for {'C': 57, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.832 (+/-0.014) for {'C': 59, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.829 (+/-0.019) for {'C': 59, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.834 (+/-0.018) for {'C': 59, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.808 (+/-0.024) for {'C': 59, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.768 (+/-0.077) for {'C': 59, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      1353\n",
      "           1       0.77      0.76      0.76       723\n",
      "\n",
      "    accuracy                           0.84      2076\n",
      "   macro avg       0.82      0.82      0.82      2076\n",
      "weighted avg       0.84      0.84      0.84      2076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_Train = scaler.fit_transform(X_Train)\n",
    "X_Test = scaler.fit_transform(X_Test)\n",
    "tuned_parameters = [{'kernel': ['poly'], 'degree': [1,2,3,4,5], 'C': [(i*2)+1 for i in range(30)], 'gamma': ['auto']}]\n",
    "\n",
    "print(\"Tuning hyper-parameters for accuracy\")\n",
    "print()\n",
    "polynomialSVM = GridSearchCV(SVC(), tuned_parameters, scoring = 'accuracy')\n",
    "polynomialSVM.fit(X_Train, Y_Train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(polynomialSVM.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = polynomialSVM.cv_results_['mean_test_score']\n",
    "stds = polynomialSVM.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, polynomialSVM.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "actualValues, predictedValues = Y_Test, polynomialSVM.predict(X_Test)\n",
    "print(classification_report(actualValues, predictedValues))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is training...\n",
      "Training complete\n",
      "[[1189  164]\n",
      " [ 175  548]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      1353\n",
      "           1       0.77      0.76      0.76       723\n",
      "\n",
      "    accuracy                           0.84      2076\n",
      "   macro avg       0.82      0.82      0.82      2076\n",
      "weighted avg       0.84      0.84      0.84      2076\n",
      "\n",
      "Accuracy score: 83.67%\n",
      "F1 score:  76.38%\n"
     ]
    }
   ],
   "source": [
    "print('Model is training...')\n",
    "\n",
    "polynomialSVM = SVC(C=59, kernel='poly', degree = 3, gamma='auto')\n",
    "polynomialSVM.fit(X_Train, Y_Train)\n",
    "predictedValues = polynomialSVM.predict(X_Test)\n",
    "\n",
    "print('Training complete')    \n",
    "print(confusion_matrix(Y_Test, predictedValues))\n",
    "print(classification_report(Y_Test, predictedValues))\n",
    "print(\"Accuracy score:\", \"{:.2%}\".format(accuracy_score(Y_Test, predictedValues)))\n",
    "print(\"F1 score: \", \"{:.2%}\".format(f1_score(Y_Test, predictedValues)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Basis Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the RBF Kernalized SVM, there are two hyperparameters to optimize: gamma, and C. Gamma, the new term, defines how much influence a support vector has on the model. If gamma is low, this means the 'sphere' of influence of that sample will be significant, whereas if it's high, the sphere of influence will be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.779 (+/-0.021) for {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.653 (+/-0.001) for {'C': 100.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.653 (+/-0.001) for {'C': 100.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.817 (+/-0.015) for {'C': 1000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.779 (+/-0.021) for {'C': 1000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.653 (+/-0.001) for {'C': 1000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.824 (+/-0.017) for {'C': 10000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.817 (+/-0.015) for {'C': 10000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.778 (+/-0.020) for {'C': 10000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.832 (+/-0.024) for {'C': 100000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.824 (+/-0.018) for {'C': 100000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.817 (+/-0.016) for {'C': 100000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.838 (+/-0.018) for {'C': 1000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.832 (+/-0.023) for {'C': 1000000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.016) for {'C': 1000000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.839 (+/-0.019) for {'C': 10000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.833 (+/-0.018) for {'C': 10000000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.820 (+/-0.009) for {'C': 10000000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.842 (+/-0.022) for {'C': 100000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.833 (+/-0.022) for {'C': 100000000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.815 (+/-0.014) for {'C': 100000000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1401\n",
      "           1       0.76      0.72      0.74       675\n",
      "\n",
      "    accuracy                           0.83      2076\n",
      "   macro avg       0.81      0.81      0.81      2076\n",
      "weighted avg       0.83      0.83      0.83      2076\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.732 (+/-0.025) for {'C': 100.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.395 (+/-0.000) for {'C': 100.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.395 (+/-0.000) for {'C': 100.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.807 (+/-0.015) for {'C': 1000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.732 (+/-0.025) for {'C': 1000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.395 (+/-0.000) for {'C': 1000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.813 (+/-0.017) for {'C': 10000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.807 (+/-0.015) for {'C': 10000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.730 (+/-0.023) for {'C': 10000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.822 (+/-0.024) for {'C': 100000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.017) for {'C': 100000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.807 (+/-0.016) for {'C': 100000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.828 (+/-0.017) for {'C': 1000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.024) for {'C': 1000000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.812 (+/-0.014) for {'C': 1000000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.828 (+/-0.017) for {'C': 10000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.018) for {'C': 10000000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.811 (+/-0.009) for {'C': 10000000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.022) for {'C': 100000000.0, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.022) for {'C': 100000000.0, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.808 (+/-0.014) for {'C': 100000000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1401\n",
      "           1       0.76      0.72      0.74       675\n",
      "\n",
      "    accuracy                           0.83      2076\n",
      "   macro avg       0.81      0.81      0.81      2076\n",
      "weighted avg       0.83      0.83      0.83      2076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-5, 1e-6, 1e-7],\n",
    "                     'C': [1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8]}]\n",
    "scores = ['accuracy', 'f1']\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    if score == 'accuracy':\n",
    "        RBF_SVM = GridSearchCV(SVC(), tuned_parameters, scoring = 'accuracy')\n",
    "    else:\n",
    "        RBF_SVM = GridSearchCV(SVC(), tuned_parameters, scoring = '%s_macro' % score)          \n",
    "    RBF_SVM.fit(X_Train, Y_Train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(RBF_SVM.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = RBF_SVM.cv_results_['mean_test_score']\n",
    "    stds = RBF_SVM.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, RBF_SVM.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print()\n",
    "    actualValues, predictedValues = Y_Test, RBF_SVM.predict(X_Test)\n",
    "    print(classification_report(actualValues, predictedValues))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1245  156]\n",
      " [ 188  487]]\n",
      "\n",
      "Accuracy score: 83.43%\n",
      "F1 score:  73.90%\n"
     ]
    }
   ],
   "source": [
    "RBF_SVM = SVC(kernel=\"rbf\", gamma= 1e-5, C=1e8)\n",
    "RBF_SVM.fit(X_Train, Y_Train)\n",
    "predictedValues = RBF_SVM.predict(X_Test)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(Y_Test, predictedValues))\n",
    "print()\n",
    "print(\"Accuracy score:\", \"{:.2%}\".format(accuracy_score(Y_Test, predictedValues)))\n",
    "print(\"F1 score: \", \"{:.2%}\".format(f1_score(Y_Test, predictedValues)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      koi_steff  koi_slogg  koi_smet  koi_srad  koi_smass koi_disposition\n",
      "0        5455.0      4.467      0.14     0.927      0.919               1\n",
      "1        5455.0      4.467      0.14     0.927      0.919               1\n",
      "3        5805.0      4.564     -0.52     0.791      0.836               0\n",
      "4        6031.0      4.438      0.07     1.046      1.095               1\n",
      "5        6046.0      4.486     -0.08     0.972      1.053               1\n",
      "...         ...        ...       ...       ...        ...             ...\n",
      "9557     5263.0      4.574     -0.66     0.699      0.668               0\n",
      "9558     5638.0      4.296     -0.16     1.088      0.856               0\n",
      "9559     5638.0      4.529      0.14     0.903      1.005               0\n",
      "9561     6173.0      4.447     -0.04     1.041      1.104               0\n",
      "9563     6469.0      4.385      0.07     1.193      1.260               0\n",
      "\n",
      "[6919 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "stellarDF = pd.concat([stellarDF, Y], axis = 1)\n",
    "print(stellarDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows that have 'false positive' labeling for planets. Will only keep stars that are confirmed to have planets around them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      koi_steff  koi_slogg  koi_smet  koi_srad  koi_smass koi_disposition\n",
      "0        5455.0      4.467      0.14     0.927      0.919               1\n",
      "1        5455.0      4.467      0.14     0.927      0.919               1\n",
      "4        6031.0      4.438      0.07     1.046      1.095               1\n",
      "5        6046.0      4.486     -0.08     0.972      1.053               1\n",
      "6        6046.0      4.486     -0.08     0.972      1.053               1\n",
      "...         ...        ...       ...       ...        ...             ...\n",
      "7658     5970.0      4.317      0.10     1.200      1.089               1\n",
      "8817     3236.0      5.097      0.00     0.193      0.169               1\n",
      "8956     3327.0      5.113     -0.38     0.189      0.169               1\n",
      "9014     5579.0      4.580     -0.22     0.798      0.892               1\n",
      "9083     5713.0      4.541      0.07     0.893      1.010               1\n",
      "\n",
      "[2357 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "stellarDF.drop(stellarDF[stellarDF['koi_disposition'] == 0].index, inplace = True)\n",
    "print(stellarDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(stellarDF['koi_steff'], stellarDF['koi_smass'], color = 'black')\n",
    "plt.ylabel(\"Solar masses (1 solar mass = 2e30 kg)\")\n",
    "plt.xlabel(\"Effective Temperature (Kelvin)\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellarStandard = MinMaxScaler().fit_transform(stellarDF)\n",
    "stellarStandard = np.delete(stellarStandard, -1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(point1, point2):\n",
    "    distance = 0\n",
    "    for j in range(5):\n",
    "        distance += (point1[j] - point2[j])**2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "class K_Means_Clustering:\n",
    "    def __init__(self, k, maxIterations):\n",
    "        self.k = k\n",
    "        self.maxIter = maxIterations\n",
    "        self.currentIteration = 0\n",
    "     \n",
    "    #This updates the centroids by having their 5-dimensional coordinates equal the mean of each column\n",
    "    #As an example, for centroid #1, it's 0th coordinate will equal the mean of the zeroth column of it's samples, \n",
    "    #it's 1st coordinate will equal the mean of the 1st column, etc. It will do this for each coordinate, for every centroid\n",
    "    def updateCentroids(self):\n",
    "        index = 0\n",
    "        self.oldCentroids = deepcopy(self.centroids)\n",
    "        for key in self.classes:\n",
    "            if self.k == 1:\n",
    "                self.centroids = np.mean(self.classes[key], axis = 1)\n",
    "            else:\n",
    "                self.centroids[index] = np.mean(self.classes[key], axis = 0)\n",
    "                index += 1\n",
    "    \n",
    "    #This classifies each row of the feature matrix, self-explanatory            \n",
    "    def classifyRow(self, row):\n",
    "        intermediate = self.findDistances(self.featureMatrix[row])\n",
    "        centroidDistances = self.SortTuple(intermediate)\n",
    "        return centroidDistances[0]\n",
    "     \n",
    "    #This sorts the tuples in the array based on the first element (smallets to largest), the distance. \n",
    "    #It then returns the first element, which represents the closest centroid \n",
    "    def SortTuple(self, tupleList):\n",
    "        return sorted(tupleList, key = lambda x: x[0])\n",
    "    \n",
    "    #This uses the distance metric to find the distance of each sample to all the centroids, and then stores the distance\n",
    "    #and class in a tuple\n",
    "    def findDistances(self, row):\n",
    "        distanceArray = []\n",
    "        if self.k == 1:\n",
    "            loop = 1\n",
    "        else:\n",
    "            loop = self.centroids.shape[0]\n",
    "        for centroid in range(loop):\n",
    "            if (self.distanceMetric == \"euclidean\"):\n",
    "                if (loop == 1):\n",
    "                    distanceArray.append(tuple([euclideanDistance(row, self.centroids),str(centroid)]))\n",
    "                else:\n",
    "                    distanceArray.append(tuple([euclideanDistance(row, self.centroids[centroid]),str(centroid)]))\n",
    "        return distanceArray\n",
    "    \n",
    "    #Convergence criteria\n",
    "    #This calculates the mean of each centroid. If the percent difference between the previous mean and the new mean \n",
    "    #are less than 0.1%, then the algorithm will stop\n",
    "    def convergence(self):\n",
    "        if self.k == 1:\n",
    "            oldMean = [np.mean(self.oldCentroids)]\n",
    "            newMean = [np.mean(self.centroids)]\n",
    "            loop = 1\n",
    "        else:\n",
    "            oldMean = np.mean(self.oldCentroids, axis = 1) #returns array of row means\n",
    "            newMean = np.mean(self.centroids, axis = 1)\n",
    "            loop = oldMean.shape[0]\n",
    "        percentDifference = []\n",
    "        for i in range(loop):\n",
    "            percentDifference.append(abs((newMean[i] - oldMean[i])/oldMean[i]))\n",
    "        if np.amax(percentDifference) <= 0.001:\n",
    "            print(percentDifference)\n",
    "            print(\"Converged at iteration:\", self.currentIteration)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def cluster(self, featureMatrix, distanceMetric):\n",
    "        self.distanceMetric = distanceMetric\n",
    "        self.featureMatrix = featureMatrix\n",
    "        self.n_rows, self.n_columns = featureMatrix.shape\n",
    "\n",
    "        #Centroid initialization\n",
    "        #This will generate a matrix of k x m matrix of centroids\n",
    "        self.centroids = np.array([])\n",
    "        for value in range(self.k):\n",
    "            randomRow = randrange(self.n_rows)\n",
    "            if value == 0:\n",
    "                self.centroids = np.append(self.centroids, np.copy(self.featureMatrix[randomRow]))\n",
    "            else:\n",
    "                self.centroids = np.vstack((self.centroids, np.copy(self.featureMatrix[randomRow])))\n",
    "        \n",
    "        #This dictionary object will hold each centroid as the key, and it's values will be the samples that belong to it\n",
    "        #Thus, this will be a dictionary of numpy arrays\n",
    "            self.classes = {}\n",
    "            \n",
    "        #This is the bulk of where the calculations happen    \n",
    "        for iteration in range(self.maxIter):\n",
    "            #if self.currentIteration%10 == 0:\n",
    "                #print(\"Current iteration: \", self.currentIteration)\n",
    "            self.classes.clear()\n",
    "            for row in range(self.n_rows):\n",
    "                distanceValue, starClass = self.classifyRow(row)\n",
    "                if starClass in self.classes:\n",
    "                    self.classes[starClass] = np.vstack((self.classes[starClass],self.featureMatrix[row]))\n",
    "                else:\n",
    "                    self.classes[starClass] = np.copy(self.featureMatrix[row])\n",
    "            self.updateCentroids()\n",
    "            if self.convergence() == True:\n",
    "                return self.classes\n",
    "            self.currentIteration += 1 \n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Elbow Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow method is a relatively simple tuning algorithm. For K-means, the only hyperparameter that has to be tuned is \"k\", the number of clusters. What the elbow method does is plot the mean squared distance each sample has to it's respective centroid against the number of clusters being used. For K-means, as the number of clusters increase, the average squared distance from any sample to a cluster centroid should decrease. At first that inverse relationship is linear, but eventually, it becomes polynomial. The point where that relationship stops being linear is the \"elbow\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on cluster:  1\n",
      "[0.0]\n",
      "Converged at iteration: 1\n",
      "[0.0]\n",
      "Converged at iteration: 1\n",
      "[0.0]\n",
      "Converged at iteration: 1\n",
      "[0.0]\n",
      "Converged at iteration: 1\n",
      "[0.0]\n",
      "Converged at iteration: 1\n",
      "Now on cluster:  2\n",
      "[0.00013934145346223612, 0.0008946350936014142]\n",
      "Converged at iteration: 8\n",
      "[4.570066217222471e-05, 0.0009591446687093574]\n",
      "Converged at iteration: 7\n",
      "[3.151841571159264e-05, 0.0009225114411424311]\n",
      "Converged at iteration: 6\n",
      "[6.28334961796227e-05, 0.00099969710134734]\n",
      "Converged at iteration: 6\n",
      "[0.0003838601925341419, 0.0008732531535996981]\n",
      "Converged at iteration: 11\n",
      "Now on cluster:  3\n",
      "[0.0005461988477313067, 0.0005567658060392288, 0.0006965188451195955]\n",
      "Converged at iteration: 8\n",
      "[1.529577424285934e-05, 8.257754115422848e-05, 0.0004087274670446182]\n",
      "Converged at iteration: 5\n",
      "[0.0007380907629108355, 0.0008792873561178056, 0.0006621642797685146]\n",
      "Converged at iteration: 3\n",
      "[0.0003201046844499244, 0.0009500392691642447, 1.525861874310024e-05]\n",
      "Converged at iteration: 7\n",
      "[8.628302624620661e-06, 0.00023687452470662676, 0.0003155375033594703]\n",
      "Converged at iteration: 11\n",
      "Now on cluster:  4\n",
      "[0.000186907157551986, 0.0003219151048999249, 0.00024381766937389327, 0.00055363053379732]\n",
      "Converged at iteration: 7\n",
      "[8.435880388157121e-05, 0.00041513001921899347, 0.0008550614553421631, 0.00024247459556965515]\n",
      "Converged at iteration: 26\n",
      "[8.900684355609926e-05, 0.0001299752196927552, 0.0005069675972597891, 7.2352628346243e-05]\n",
      "Converged at iteration: 14\n",
      "[0.00012145435432400288, 0.0003919720672866892, 0.0009965092036369725, 0.00024247459556965515]\n",
      "Converged at iteration: 10\n",
      "[0.00011771199690314075, 0.0001870110408925856, 0.0, 0.0]\n",
      "Converged at iteration: 27\n",
      "Now on cluster:  5\n",
      "[0.0005255323472533189, 0.00019292384702767528, 0.0005882816859590061, 0.00032662411976435183, 0.0008373770029373822]\n",
      "Converged at iteration: 10\n",
      "[0.0008729775116101391, 0.00033073548825493157, 0.00011293821250511291, 8.103892929995028e-05, 8.691537358592367e-05]\n",
      "Converged at iteration: 11\n",
      "[0.00012780542814819503, 0.00059274270655076, 0.0005318088793334193, 0.0001252592518888109, 0.0]\n",
      "Converged at iteration: 17\n",
      "[5.621960808354697e-05, 0.00018792893199571202, 2.40200643137585e-06, 0.0003374887535587476, 0.0]\n",
      "Converged at iteration: 15\n",
      "[0.0002997714052222792, 2.6103161711308058e-05, 8.49395679990533e-05, 0.00016757574582867255, 0.0007754087544393752]\n",
      "Converged at iteration: 14\n",
      "Now on cluster:  6\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Converged at iteration: 17\n",
      "[0.00031937931624740885, 0.00025149540556849916, 1.413671589122669e-06, 0.00045310298954791685, 9.477602164342714e-05, 0.0]\n",
      "Converged at iteration: 13\n",
      "[0.00019492122439861175, 1.3775386270938511e-05, 4.695498593079321e-05, 0.0003462303998830949, 0.00035207487692435417, 0.0003727993755435382]\n",
      "Converged at iteration: 9\n",
      "[3.800199251055804e-05, 0.00042819754497302006, 6.378797899509173e-05, 0.0005472131232566913, 0.0, 0.0]\n",
      "Converged at iteration: 17\n",
      "[0.00041829782932750124, 0.0004901116165729708, 0.0006308718489119836, 0.0007222173207533482, 0.0005093790823331371, 0.0]\n",
      "Converged at iteration: 11\n",
      "Now on cluster:  7\n",
      "[0.0008054688289483869, 5.2569309455174875e-05, 0.0, 0.0007960510044274227, 0.0004053693697284559, 0.0, 0.0]\n",
      "Converged at iteration: 18\n",
      "[0.0009745994131121049, 7.255802807433918e-05, 0.0, 0.0008595046399772204, 0.0004628152784551145, 0.00030367141859026557, 0.0]\n",
      "Converged at iteration: 14\n",
      "[0.00018524923789888236, 0.00023845026005414073, 0.00017017107570776408, 0.00012436494937811667, 0.0, 0.0, 0.0005073937073207141]\n",
      "Converged at iteration: 10\n",
      "[0.0001583185931584247, 2.7667799508594008e-05, 0.0002581829146818555, 0.0004734314725906451, 0.0, 0.0, 0.0]\n",
      "Converged at iteration: 14\n",
      "[0.00015599111208071376, 0.00010852162746919303, 0.00015470138071041977, 1.3911249621032824e-05, 2.210802870163276e-05, 7.399306672942015e-05, 0.00012503465360254467]\n",
      "Converged at iteration: 9\n",
      "Now on cluster:  8\n",
      "[0.00018270280044794848, 2.3844349421947642e-05, 3.6901571711855305e-05, 0.0002572797870308833, 0.0, 0.00016539675534048254, 0.0, 0.0]\n",
      "Converged at iteration: 17\n",
      "[0.0003390178963195001, 0.00040966486518461125, 5.063489636391279e-05, 0.000923064245177548, 0.00021661591600141832, 0.0006520875220791276, 0.0008868842327941449, 0.0]\n",
      "Converged at iteration: 53\n",
      "[5.1379432202536886e-05, 0.0001405604781057577, 0.0007947474646833204, 0.0, 0.000830647353196662, 0.0006162475519521176, 0.00018127894655936452, 0.00012503465360254467]\n",
      "Converged at iteration: 12\n",
      "[0.00041388061228060083, 0.00010893630140357815, 8.844137941054155e-05, 0.00036072185474530534, 0.0003009262588943895, 0.000438701733525927, 0.0, 0.0007243154991196907]\n",
      "Converged at iteration: 13\n",
      "[0.000276400076586243, 0.0004167910035261077, 0.00020965743379425773, 0.0001370013852347771, 0.0006156856017065904, 0.000490388704254347, 0.0, 0.0]\n",
      "Converged at iteration: 22\n",
      "Now on cluster:  9\n",
      "[0.0003745410933642484, 0.0007792924936612015, 0.0007327993112590966, 0.0, 0.0005547257485740363, 7.022998069538412e-05, 0.0, 0.000987599357415793, 0.0006266803513963436]\n",
      "Converged at iteration: 9\n",
      "[3.995340376871094e-05, 0.00035346904543859925, 5.292350736979689e-05, 0.00028208180852177194, 0.0, 0.0, 0.00019193344136895352, 0.0, 0.0]\n",
      "Converged at iteration: 24\n",
      "[0.00016617724293299522, 0.0003073314897289451, 3.798264442896386e-05, 0.0008136638973497813, 0.0, 0.0004183560092779735, 0.0, 0.0, 0.0]\n",
      "Converged at iteration: 11\n",
      "[0.0004327375393899511, 5.574771110129184e-06, 0.00014716741384016447, 0.0, 0.00021579696352792252, 0.0, 0.0, 0.0, 0.0]\n",
      "Converged at iteration: 14\n",
      "[2.9925539444219263e-05, 0.0002530110106745278, 0.0, 0.00036403735883346435, 0.0, 0.0004016280211084776, 0.0, 0.0, 0.0]\n",
      "Converged at iteration: 16\n",
      "Now on cluster:  10\n",
      "[3.1684614187840267e-06, 8.884887122271344e-05, 0.0, 0.000934113217491906, 0.0, 8.554644498061836e-05, 0.0, 0.0, 0.00037792326309630294, 0.0]\n",
      "Converged at iteration: 15\n",
      "[5.470534810886664e-05, 0.0004977856145021511, 0.0001890027967611004, 0.0005121332836375207, 0.0008604914855528574, 0.0, 0.0003127823579240405, 0.0, 0.0, 0.0]\n",
      "Converged at iteration: 23\n",
      "[0.00027654489489781095, 9.9763508385427e-05, 0.0, 0.0, 0.0, 0.00030195491602133463, 0.0002934062115679226, 0.0, 4.0121634592650175e-05, 0.0]\n",
      "Converged at iteration: 25\n",
      "[0.0003400100346766625, 0.00017355160468917775, 8.434079139858964e-05, 5.289108605345527e-05, 0.0, 0.0003342874531397206, 6.890719909432643e-05, 0.0, 0.0007126109835281556, 0.0]\n",
      "Converged at iteration: 15\n",
      "[8.17060371731145e-05, 0.00037151054613789784, 0.0001252042036058425, 7.089329691899853e-05, 0.0004928677042521875, 0.0006803740231424131, 4.625069227084256e-05, 0.0, 0.0003596696765703026, 0.0]\n",
      "Converged at iteration: 13\n"
     ]
    }
   ],
   "source": [
    "clusterArray = [1,2,3,4,5,6,7,8,9,10]\n",
    "def elbowMethod(clusterArray, featureMatrix, maxIter):\n",
    "    inertiaMatrix = np.array([])\n",
    "    for cluster in clusterArray:\n",
    "        inertia = np.array([])\n",
    "        print(\"Now on cluster: \", cluster)\n",
    "        for i in range(5):\n",
    "            kMeansElbow = K_Means_Clustering(cluster, maxIter)\n",
    "            predictions = kMeansElbow.cluster(featureMatrix, \"euclidean\")\n",
    "            for key in predictions:\n",
    "                inertia = np.append(inertia, np.sum(np.square(predictions[key])))\n",
    "        inertia = np.mean(inertia)\n",
    "        inertia = np.append(inertia, cluster)\n",
    "        if inertiaMatrix.size == 0:\n",
    "            inertiaMatrix = np.append(inertiaMatrix, inertia)\n",
    "        else:\n",
    "            inertiaMatrix = np.vstack((inertiaMatrix, inertia))\n",
    "    return inertiaMatrix\n",
    "\n",
    "plotArray = elbowMethod(clusterArray, stellarStandard, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(plotArray[:,1], plotArray[:,0])\n",
    "plt.xticks(np.arange(min(plotArray[:,1]), max(plotArray[:,1] +1), 1.0))\n",
    "plt.xlabel(\"Cluster Centroid count (k)\")\n",
    "plt.ylabel(\"Mean squared distances\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow for this curve is at k = 3, therefore future instances of K-Means for this dataset will use k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.653927230778627e-05, 0.00013149124839322544, 0.0008747133894885526]\n",
      "Converged at iteration: 23\n",
      "Clustering complete!\n"
     ]
    }
   ],
   "source": [
    "kMeans = K_Means_Clustering(3, 200)\n",
    "predictedValues = kMeans.cluster(stellarStandard, \"euclidean\")\n",
    "print(\"Clustering complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1065, 5)\n",
      "(894, 5)\n",
      "(398, 5)\n"
     ]
    }
   ],
   "source": [
    "print(predictedValues['0'].shape)\n",
    "print(predictedValues['1'].shape)\n",
    "print(predictedValues['2'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
